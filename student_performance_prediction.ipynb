{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Performance Prediction\n",
    "\n",
    "This notebook aims to predict student performance based on various factors such as hours studied, previous scores, extracurricular activities, sleep hours, and question papers practiced. We will focus on creating a model that provides realistic (\"humanised\") and unbiased predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Set style for plots\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'student_ml/performance/dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "We'll visualize the distributions and potential relationships between variables, with a specific focus on \"Hours Studied\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between Hours Studied and Performance Index\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Hours Studied', y='Performance Index', alpha=0.6)\n",
    "plt.title('Hours Studied vs. Performance Index')\n",
    "plt.xlabel('Hours Studied')\n",
    "plt.ylabel('Performance Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "# First convert categorical 'Extracurricular Activities' to numeric for correlation\n",
    "df_corr = df.copy()\n",
    "df_corr['Extracurricular Activities'] = df_corr['Extracurricular Activities'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df_corr.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing\n",
    "\n",
    "We need to encode the categorical variable `Extracurricular Activities` and split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Variable\n",
    "df['Extracurricular Activities'] = df['Extracurricular Activities'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Defining Features (X) and Target (y)\n",
    "X = df.drop('Performance Index', axis=1)\n",
    "y = df['Performance Index']\n",
    "\n",
    "# Splitting the Data (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling (Linear Regression)\n",
    "\n",
    "We'll use Linear Regression as it allows for easy interpretability, which is crucial for understanding how each factor (like hours studied) contributes to the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and Train Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients Interpretation\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Humanised Predictions\n",
    "\n",
    "We evaluate the model using standard metrics. To ensure \"humanised\" predictions:\n",
    "1. We clip predictions to be within the valid range [0, 100].\n",
    "2. We round predictions to the nearest integer, as scores are typically whole numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "y_pred_raw = model.predict(X_test)\n",
    "\n",
    "# Humanise Predictions: Clip to [0, 100] and Round\n",
    "y_pred_humanised = np.clip(y_pred_raw, 0, 100)\n",
    "y_pred_humanised = np.round(y_pred_humanised)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred_humanised)\n",
    "mse = mean_squared_error(y_test, y_pred_humanised)\n",
    "r2 = r2_score(y_test, y_pred_humanised)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bias Check\n",
    "\n",
    "We check the residuals to ensure there are no systematic errors. A \"good\" unbiased model should have normally distributed residuals centered around zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred_raw\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.xlabel('Residual (Actual - Predicted)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example Prediction\n",
    "Let's test the model with a hypothetical student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Student who studies 7 hours, previous score 80, does extracurriculars, sleeps 8 hours, practiced 5 papers.\n",
    "new_student = pd.DataFrame({\n",
    "    'Hours Studied': [7],\n",
    "    'Previous Scores': [80],\n",
    "    'Extracurricular Activities': [1], # Yes\n",
    "    'Sleep Hours': [8],\n",
    "    'Sample Question Papers Practiced': [5]\n",
    "})\n",
    "\n",
    "prediction = model.predict(new_student)\n",
    "final_score = np.clip(np.round(prediction[0]), 0, 100)\n",
    "\n",
    "print(f\"Predicted Performance Index: {final_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
